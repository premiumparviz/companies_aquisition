{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report on Binary Classification Model to Predict Company Acquisitions\n",
    "\n",
    "## Introduction\n",
    "The objective of this project was to develop a binary classification model to predict whether a company will be acquired. The prediction was based on various features provided in the dataset. The task commenced with the application of logistic regression and random forest models using only numerical data. The aim was to identify the more effective algorithm for this specific classification task.\n",
    "\n",
    "## Methodology\n",
    "### Initial Model Selection:\n",
    "- We started with logistic regression and random forest models, focusing solely on the numerical attributes of the dataset.\n",
    "- The models' performance was evaluated to determine the most suitable approach for this prediction task.\n",
    "\n",
    "### Incorporation of Categorical Data:\n",
    "- To enhance the model's predictive power, categorical data, including industry and address_country_code, were incorporated.\n",
    "- The keywords column, a text-based feature, was also added after appropriate preprocessing using TF-IDF vectorization and PCA for dimensionality reduction.\n",
    "\n",
    "### Model Training and Validation:\n",
    "- The dataset was divided into training (80%), validation (10%), and test (10%) sets. This division ensured a robust evaluation framework.\n",
    "- Random forest was used as the primary model due to its superior performance in the initial evaluation.\n",
    "- Hyperparameter tuning was performed using RandomizedSearchCV to optimize the random forest model.\n",
    "\n",
    "### Ensemble Model Creation:\n",
    "- An ensemble model comprising different tree-based algorithms, including the tuned Random Forest, Gradient Boosting, and Extra Trees classifiers, was created.\n",
    "- The ensemble approach aimed to improve model robustness and predictive accuracy.\n",
    "\n",
    "### Threshold Optimization and Model Evaluation:\n",
    "- The optimal threshold for classification was determined using the validation set. This approach aimed to maximize the F1 score, a crucial metric for binary classification tasks.\n",
    "- Both the tuned random forest and the ensemble model were evaluated on the test set using this optimal threshold.\n",
    "\n",
    "## Results and Discussion\n",
    "- The random forest model demonstrated a superior performance compared to logistic regression in the initial phase, prompting its selection for further analysis and enhancement.\n",
    "- Incorporating categorical data, especially the industry and keywords attributes, significantly improved the model's predictive accuracy. This improvement highlighted the importance of these features in predicting company acquisitions.\n",
    "- The fine-tuned random forest model and the ensemble of tree-based models were robust, as evidenced by their performance on the test set. The models achieved an F1 score of approximately 0.71, indicating a strong balance between precision and recall.\n",
    "- The use of a separate validation set for threshold optimization proved beneficial in enhancing the model's performance on unseen data. This approach ensured that the threshold tuning did not overfit the training data and was genuinely reflective of the model's capability to generalize.\n",
    "\n",
    "## Conclusion\n",
    "The project successfully developed a robust binary classification model capable of predicting company acquisitions with a high degree of accuracy. The integration of categorical data and the adoption of advanced modeling techniques, including ensemble modeling and optimal threshold determination, were key to achieving this high level of performance. The final model, with an F1 score of around 0.71, stands as a testament to the efficacy of these methods in tackling complex predictive tasks in the realm of business acquisitions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "Accuracy: 0.6169686985172982\n",
      "Precision: 0.5801526717557252\n",
      "Recall: 0.15637860082304528\n",
      "F1 Score: 0.24635332252836306\n",
      "Average Precision: 0.5505941169599564\n",
      "ROC AUC: 0.6881465371048704\n",
      "\n",
      "Random Forest:\n",
      "Accuracy: 0.6540362438220758\n",
      "Precision: 0.5901639344262295\n",
      "Recall: 0.4444444444444444\n",
      "F1 Score: 0.5070422535211268\n",
      "Average Precision: 0.5888375048068542\n",
      "ROC AUC: 0.6793073503142948\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, classification_report,\n",
    "                             average_precision_score, roc_auc_score,\n",
    "                             precision_recall_fscore_support)\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'C:\\\\Users\\\\Parviz\\\\data_DEAN\\\\all_comp_csv\\\\all_comp.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Dropping less relevant columns for simplicity\n",
    "data_reduced = data.drop(['company_name', 'website_standard', 'description', 'address_city', 'address_admin1_name', 'industry', 'address_country_code', 'keywords'], axis=1)\n",
    "\n",
    "# Encoding categorical variables\n",
    "categorical_columns = data_reduced.select_dtypes(include=['object']).columns\n",
    "for col in categorical_columns:\n",
    "    data_reduced[col] = LabelEncoder().fit_transform(data_reduced[col])\n",
    "\n",
    "# Select features and target variable\n",
    "X = data_reduced.drop('acquired', axis=1)\n",
    "y = data_reduced['acquired']\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Logistic Regression Model\n",
    "# -------------------------\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "y_pred_lr = log_reg.predict(X_test_scaled)\n",
    "y_pred_proba_lr = log_reg.predict_proba(X_test_scaled)[:, 1]  # probabilities for the positive class\n",
    "\n",
    "# Evaluate the logistic regression model\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "average_precision_lr = average_precision_score(y_test, y_pred_proba_lr)\n",
    "roc_auc_lr = roc_auc_score(y_test, y_pred_proba_lr)\n",
    "precision_lr, recall_lr, f1_score_lr, _ = precision_recall_fscore_support(y_test, y_pred_lr, average='binary')\n",
    "\n",
    "# Random Forest Model\n",
    "# --------------------\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "random_forest.fit(X_train_scaled, y_train)\n",
    "y_pred_rf = random_forest.predict(X_test_scaled)\n",
    "y_pred_proba_rf = random_forest.predict_proba(X_test_scaled)[:, 1]  # probabilities for the positive class\n",
    "\n",
    "# Evaluate the Random Forest model\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "average_precision_rf = average_precision_score(y_test, y_pred_proba_rf)\n",
    "roc_auc_rf = roc_auc_score(y_test, y_pred_proba_rf)\n",
    "precision_rf, recall_rf, f1_score_rf, _ = precision_recall_fscore_support(y_test, y_pred_rf, average='binary')\n",
    "\n",
    "# Display results\n",
    "print(\"Logistic Regression:\")\n",
    "print(\"Accuracy:\", accuracy_lr)\n",
    "print(\"Precision:\", precision_lr)\n",
    "print(\"Recall:\", recall_lr)\n",
    "print(\"F1 Score:\", f1_score_lr)\n",
    "print(\"Average Precision:\", average_precision_lr)\n",
    "print(\"ROC AUC:\", roc_auc_lr)\n",
    "\n",
    "print(\"\\nRandom Forest:\")\n",
    "print(\"Accuracy:\", accuracy_rf)\n",
    "print(\"Precision:\", precision_rf)\n",
    "print(\"Recall:\", recall_rf)\n",
    "print(\"F1 Score:\", f1_score_rf)\n",
    "print(\"Average Precision:\", average_precision_rf)\n",
    "print(\"ROC AUC:\", roc_auc_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n",
      "Best parameters found:  {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "Best Random Forest Model:\n",
      "Accuracy: 0.6820428336079077\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # Example: number of trees in the forest\n",
    "    'max_depth': [10, 20, 30],        # Example: maximum depth of each tree\n",
    "    'min_samples_split': [2, 5, 10],  # Example: minimum number of samples required to split a node\n",
    "    'min_samples_leaf': [1, 2, 4]     # Example: minimum number of samples required at each leaf node\n",
    "}\n",
    "\n",
    "# Create a base model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, \n",
    "                           cv=3, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best parameters found\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Evaluate the best model\n",
    "best_grid = grid_search.best_estimator_\n",
    "y_pred_best = best_grid.predict(X_test_scaled)\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "\n",
    "# Display results\n",
    "print(\"Best Random Forest Model:\")\n",
    "print(\"Accuracy:\", accuracy_best)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest:\n",
      "Accuracy: 0.6820428336079077\n",
      "Precision: 0.6592356687898089\n",
      "Recall: 0.42592592592592593\n",
      "F1 Score: 0.5175000000000001\n",
      "Average Precision: 0.6422215807468983\n",
      "ROC AUC: 0.7251977061004838\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Model\n",
    "# --------------------\n",
    "y_pred_rf = best_grid.predict(X_test_scaled)\n",
    "y_pred_proba_rf = best_grid.predict_proba(X_test_scaled)[:, 1]  # probabilities for the positive class\n",
    "\n",
    "# Evaluate the Random Forest model\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "average_precision_rf = average_precision_score(y_test, y_pred_proba_rf)\n",
    "roc_auc_rf = roc_auc_score(y_test, y_pred_proba_rf)\n",
    "precision_rf, recall_rf, f1_score_rf, _ = precision_recall_fscore_support(y_test, y_pred_rf, average='binary')\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nRandom Forest:\")\n",
    "print(\"Accuracy:\", accuracy_rf)\n",
    "print(\"Precision:\", precision_rf)\n",
    "print(\"Recall:\", recall_rf)\n",
    "print(\"F1 Score:\", f1_score_rf)\n",
    "print(\"Average Precision:\", average_precision_rf)\n",
    "print(\"ROC AUC:\", roc_auc_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy with 'Industry' as a feature: 0.6742174629324547\n",
      "\n",
      "Random Forest:\n",
      "Accuracy: 0.6820428336079077\n",
      "Precision: 0.6291012838801712\n",
      "Recall: 0.4537037037037037\n",
      "F1 Score: 0.5271966527196652\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Encode the 'industry' column\n",
    "label_encoder = LabelEncoder()\n",
    "data['industry_encoded'] = label_encoder.fit_transform(data['industry'])\n",
    "\n",
    "# Prepare the dataset for training\n",
    "# Ensure all columns except 'acquired' and non-numeric columns are included\n",
    "X = data.select_dtypes(include=[np.number])\n",
    "\n",
    "# Ensure 'acquired' is not part of the features\n",
    "X = X.drop('acquired', axis=1)\n",
    "\n",
    "# Target variable\n",
    "y = data['acquired']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict and calculate accuracy\n",
    "y_pred = rf.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"Model Accuracy with 'Industry' as a feature: {accuracy}\")\n",
    "# Evaluate the Random Forest model\n",
    "precision_rf, recall_rf, f1_score_rf, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
    "print(\"\\nRandom Forest:\")\n",
    "print(\"Accuracy:\", accuracy_rf)\n",
    "print(\"Precision:\", precision_rf)\n",
    "print(\"Recall:\", recall_rf)\n",
    "print(\"F1 Score:\", f1_score_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.685337726523888\n",
      "Precision: 0.6580547112462006\n",
      "Recall: 0.4454732510288066\n",
      "F1 Score: 0.5312883435582823\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Fill NaNs in 'keywords' column\n",
    "data['keywords'] = data['keywords'].fillna('')\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "tfidf = TfidfVectorizer(max_features=100)\n",
    "keywords_tfidf = tfidf.fit_transform(data['keywords'])\n",
    "\n",
    "# Apply PCA for Dimensionality Reduction\n",
    "pca = PCA(n_components=10)  # Adjust the number of components as necessary\n",
    "keywords_pca = pca.fit_transform(keywords_tfidf.toarray())\n",
    "\n",
    "# Prepare the final dataset\n",
    "keywords_df = pd.DataFrame(keywords_pca, columns=[f'pca_{i}' for i in range(keywords_pca.shape[1])])\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data = pd.concat([data, keywords_df], axis=1)\n",
    "\n",
    "# Ensure all columns except 'acquired' are included as features\n",
    "X = data.drop(['acquired', 'company_name', 'website_standard', 'description', 'address_city', 'address_admin1_name', 'industry', 'address_country_code', 'keywords'], axis=1)\n",
    "X = X.select_dtypes(include=[np.number])\n",
    "\n",
    "# Target variable\n",
    "y = data['acquired']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict and calculate metrics\n",
    "y_pred = rf.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold (from validation set): 0.4783333333333333\n",
      "Test Set AUC: 0.7586337194533354\n",
      "Test Set F1 Score at Optimal Threshold: 0.5694682675814752\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'data' is your DataFrame and pre-processing steps have been done\n",
    "\n",
    "# Encode 'industry' column\n",
    "label_encoder = LabelEncoder()\n",
    "data['industry_encoded'] = label_encoder.fit_transform(data['industry'])\n",
    "\n",
    "# Prepare the dataset for training\n",
    "X = pd.concat([data[['industry_encoded']], keywords_df], axis=1)\n",
    "X = pd.concat([X, data.select_dtypes(include=[np.number]).drop(['acquired'], axis=1)], axis=1)\n",
    "y = data['acquired']\n",
    "\n",
    "# Split the data into train and temporary set (test + validation)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the temporary set into validation and test sets\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Function to find optimal threshold\n",
    "def find_optimal_threshold(y_true, y_proba):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_proba)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    return optimal_threshold\n",
    "\n",
    "# Predict probabilities on validation set and find optimal threshold\n",
    "y_val_proba = rf.predict_proba(X_val_scaled)[:, 1]\n",
    "optimal_threshold = find_optimal_threshold(y_val, y_val_proba)\n",
    "\n",
    "# Predict on test set with optimal threshold\n",
    "y_test_proba = rf.predict_proba(X_test_scaled)[:, 1]\n",
    "y_pred_test = (y_test_proba >= optimal_threshold).astype(int)\n",
    "\n",
    "# Evaluate on test set\n",
    "auc_test = roc_auc_score(y_test, y_test_proba)\n",
    "f1_test = f1_score(y_test, y_pred_test)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Optimal Threshold (from validation set): {optimal_threshold}\")\n",
    "print(f\"Test Set AUC: {auc_test}\")\n",
    "print(f\"Test Set F1 Score at Optimal Threshold: {f1_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold (from validation set): 0.36\n",
      "Test Set AUC: 0.7968424528781182\n",
      "Test Set F1 Score at Optimal Threshold: 0.7005347593582888\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "data = pd.read_csv(file_path)\n",
    "label_encoder_industry = LabelEncoder()\n",
    "data['industry_encoded'] = label_encoder_industry.fit_transform(data['industry'])\n",
    "label_encoder_country = LabelEncoder()\n",
    "data['country_encoded'] = label_encoder_country.fit_transform(data['address_country_code'])\n",
    "\n",
    "# Prepare the dataset for training\n",
    "X = pd.concat([data[['industry_encoded', 'country_encoded']], keywords_df], axis=1)\n",
    "X = pd.concat([X, data.select_dtypes(include=[np.number]).drop(['acquired'], axis=1)], axis=1)\n",
    "y = data['acquired']\n",
    "\n",
    "# Split the data into train, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Function to find optimal threshold\n",
    "def find_optimal_threshold(y_true, y_proba):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_proba)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    return optimal_threshold\n",
    "\n",
    "# Predict probabilities on validation set and find optimal threshold\n",
    "y_val_proba = rf.predict_proba(X_val_scaled)[:, 1]\n",
    "optimal_threshold = find_optimal_threshold(y_val, y_val_proba)\n",
    "\n",
    "# Predict on test set with optimal threshold\n",
    "y_test_proba = rf.predict_proba(X_test_scaled)[:, 1]\n",
    "y_pred_test = (y_test_proba >= optimal_threshold).astype(int)\n",
    "\n",
    "# Evaluate on test set\n",
    "auc_test = roc_auc_score(y_test, y_test_proba)\n",
    "f1_test = f1_score(y_test, y_pred_test)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Optimal Threshold (from validation set): {optimal_threshold}\")\n",
    "print(f\"Test Set AUC: {auc_test}\")\n",
    "print(f\"Test Set F1 Score at Optimal Threshold: {f1_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('rf',\n",
       "                              RandomForestClassifier(max_features=8,\n",
       "                                                     min_samples_leaf=5,\n",
       "                                                     min_samples_split=8,\n",
       "                                                     n_estimators=221,\n",
       "                                                     random_state=42)),\n",
       "                             ('gb',\n",
       "                              GradientBoostingClassifier(random_state=42)),\n",
       "                             ('et', ExtraTreesClassifier(random_state=42))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from scipy.stats import randint as sp_randint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "data = pd.read_csv(file_path)\n",
    "label_encoder_industry = LabelEncoder()\n",
    "data['industry_encoded'] = label_encoder_industry.fit_transform(data['industry'])\n",
    "label_encoder_country = LabelEncoder()\n",
    "data['country_encoded'] = label_encoder_country.fit_transform(data['address_country_code'])\n",
    "\n",
    "# Prepare the dataset for training\n",
    "X = pd.concat([data[['industry_encoded', 'country_encoded']], keywords_df], axis=1)\n",
    "X = pd.concat([X, data.select_dtypes(include=[np.number]).drop(['acquired'], axis=1)], axis=1)\n",
    "y = data['acquired']\n",
    "\n",
    "# Split the data into train, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Randomized Search for Hyperparameter Tuning\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "param_dist = {\n",
    "    'n_estimators': sp_randint(100, 500),\n",
    "    'max_depth': [3, None],\n",
    "    'max_features': sp_randint(1, 11),\n",
    "    'min_samples_split': sp_randint(2, 11),\n",
    "    'min_samples_leaf': sp_randint(1, 11),\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "random_search = RandomizedSearchCV(rf, param_distributions=param_dist, n_iter=10, cv=5, random_state=42)\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "rf_best = random_search.best_estimator_\n",
    "\n",
    "# Train Ensemble Model\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "et = ExtraTreesClassifier(random_state=42)\n",
    "ensemble = VotingClassifier(estimators=[('rf', rf_best), ('gb', gb), ('et', et)], voting='soft')\n",
    "ensemble.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuned Random Forest - Test Set:\n",
      "AUC: 0.805930244373317, F1 Score at Optimal Threshold: 0.701530612244898\n",
      "\n",
      "Ensemble Model - Test Set:\n",
      "AUC: 0.8082482345170959, F1 Score at Optimal Threshold: 0.7101449275362318\n"
     ]
    }
   ],
   "source": [
    "# Function to evaluate models\n",
    "def evaluate_model(model, X_scaled, y):\n",
    "    y_pred_proba = model.predict_proba(X_scaled)[:, 1]\n",
    "    auc = roc_auc_score(y, y_pred_proba)\n",
    "    fpr, tpr, thresholds = roc_curve(y, y_pred_proba)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    y_pred_optimal = (y_pred_proba >= optimal_threshold).astype(int)\n",
    "    f1_optimal = f1_score(y, y_pred_optimal)\n",
    "    return auc, optimal_threshold, f1_optimal\n",
    "\n",
    "# Fine-tune threshold on the validation set\n",
    "auc_val_rf, optimal_threshold_rf, f1_val_rf = evaluate_model(rf_best, X_val_scaled, y_val)\n",
    "auc_val_ensemble, optimal_threshold_ensemble, f1_val_ensemble = evaluate_model(ensemble, X_val_scaled, y_val)\n",
    "\n",
    "# Function to evaluate models\n",
    "def evaluate_model_with_threshold(model, X_scaled, y, optimal_threshold):\n",
    "    y_pred_proba = model.predict_proba(X_scaled)[:, 1]\n",
    "    auc = roc_auc_score(y, y_pred_proba)\n",
    "    fpr, tpr, thresholds = roc_curve(y, y_pred_proba)\n",
    "    y_pred_optimal = (y_pred_proba >= optimal_threshold).astype(int)\n",
    "    f1_optimal = f1_score(y, y_pred_optimal)\n",
    "    return auc, optimal_threshold, f1_optimal\n",
    "# Test Set Evaluation\n",
    "auc_test_rf, _, f1_test_rf = evaluate_model_with_threshold(rf_best, X_test_scaled, y_test, optimal_threshold_rf)\n",
    "auc_test_ensemble, _, f1_test_ensemble = evaluate_model_with_threshold(ensemble, X_test_scaled, y_test, optimal_threshold_ensemble)\n",
    "\n",
    "print(\"\\nTuned Random Forest - Test Set:\")\n",
    "print(f\"AUC: {auc_test_rf}, F1 Score at Optimal Threshold: {f1_test_rf}\")\n",
    "\n",
    "print(\"\\nEnsemble Model - Test Set:\")\n",
    "print(f\"AUC: {auc_test_ensemble}, F1 Score at Optimal Threshold: {f1_test_ensemble}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
